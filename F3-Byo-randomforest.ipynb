{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop, Train, Optimize and Deploy Scikit-Learn Random Forest\n",
    "\n",
    "> *This notebook should work well with the `Python 3 (Data Science)` kernel in SageMaker Studio, or the `conda_python3` kernel in SageMaker Notebook Instances*\n",
    "\n",
    "In this notebook we show how to use Amazon SageMaker to develop, train, tune and deploy a Random Forest model based using the popular ML framework [Scikit-Learn](https://scikit-learn.org/stable/index.html).\n",
    "\n",
    "The example uses the *California Housing dataset* (provided by Scikit-Learn) - more details of which can be found [here](https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html).\n",
    "\n",
    "To understand the code, you might also find it useful to refer to:\n",
    "\n",
    "* The guide on [Using Scikit-Learn with the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/using_sklearn.html)\n",
    "* The API doc for [Scikit-Learn classes in the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/sagemaker.sklearn.html)\n",
    "* The [SageMaker reference for Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#client) (The general AWS SDK for Python, including low-level bindings for SageMaker as well as many other AWS services)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libraries and environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket sagemaker-ap-southeast-2-006485324388\n"
     ]
    }
   ],
   "source": [
    "# Python Built-Ins:\n",
    "import datetime\n",
    "import tarfile\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "\n",
    "print('Using bucket ' + bucket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "We load a dataset from sklearn, split it and send it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "# we use the California housing dataset \n",
    "data = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.25, random_state=42)\n",
    "\n",
    "trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "trainX['target'] = y_train\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "testX['target'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.2143</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.288235</td>\n",
       "      <td>0.973529</td>\n",
       "      <td>860.0</td>\n",
       "      <td>2.529412</td>\n",
       "      <td>33.81</td>\n",
       "      <td>-118.12</td>\n",
       "      <td>2.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3468</td>\n",
       "      <td>42.0</td>\n",
       "      <td>6.364322</td>\n",
       "      <td>1.087940</td>\n",
       "      <td>957.0</td>\n",
       "      <td>2.404523</td>\n",
       "      <td>37.16</td>\n",
       "      <td>-121.98</td>\n",
       "      <td>2.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9191</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.110063</td>\n",
       "      <td>1.059748</td>\n",
       "      <td>711.0</td>\n",
       "      <td>2.235849</td>\n",
       "      <td>38.45</td>\n",
       "      <td>-122.69</td>\n",
       "      <td>1.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.3703</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990196</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>2.272549</td>\n",
       "      <td>34.16</td>\n",
       "      <td>-118.41</td>\n",
       "      <td>4.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.3684</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.795858</td>\n",
       "      <td>1.035503</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2.088757</td>\n",
       "      <td>38.57</td>\n",
       "      <td>-121.33</td>\n",
       "      <td>1.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  4.2143      37.0  5.288235   0.973529       860.0  2.529412     33.81   \n",
       "1  5.3468      42.0  6.364322   1.087940       957.0  2.404523     37.16   \n",
       "2  3.9191      36.0  6.110063   1.059748       711.0  2.235849     38.45   \n",
       "3  6.3703      32.0  6.000000   0.990196      1159.0  2.272549     34.16   \n",
       "4  2.3684      17.0  4.795858   1.035503       706.0  2.088757     38.57   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -118.12   2.285  \n",
       "1    -121.98   2.799  \n",
       "2    -122.69   1.830  \n",
       "3    -118.41   4.658  \n",
       "4    -121.33   1.500  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories\n",
    "! mkdir -p data\n",
    "! mkdir -p source\n",
    "! mkdir -p model\n",
    "\n",
    "# save data as csv\n",
    "trainX.to_csv('data/california_housing_train.csv')\n",
    "testX.to_csv('data/california_housing_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training script\n",
    "\n",
    "The SageMaker Scikit-Learn Framework Container provides the basic runtime, and we as users specify the actual training steps to run as a script file (or even a folder of several, perhaps including a *requirements.txt* file).\n",
    "\n",
    "The below code initializes a `.py` file from here in the notebook.\n",
    "\n",
    "The same script can be used at training time (run as a script) and inference time (imported as a module) - So below we:\n",
    "\n",
    "- Define some specific functions to override default inference behavior (e.g. `model_fn()`), and\n",
    "- Enclose the training entry point in an `if __name__ == '__main__'` *guard clause* so it only executes when the module is run as a script.\n",
    "\n",
    "You can find detailed guidance in the documentation on [Preparing a Scikit-Learn training script](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#prepare-a-scikit-learn-training-script) (for training) and the [SageMaker Scikit-Learn model server](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#sagemaker-scikit-learn-model-server) (for inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing source/sklearn_training_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source/sklearn_training_script.py\n",
    "# Python Built-Ins:\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# External Dependencies:\n",
    "#Joblib is a set of tools to provide lightweight pipelining in Python.\n",
    "# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, \n",
    "# along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "\n",
    "#  pandas is a software library written for the Python programming language for data manipulation and analysis. \n",
    "#In particular, it offers data structures and operations for manipulating numerical tables and time series.\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#A random forest is a meta estimator that fits a number of classifying decision trees \n",
    "#on various sub-samples of the dataset and uses averaging to improve the predictive accuracy \n",
    "#and control over-fitting.\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #------------------------------- parsing input parameters (from command line)\n",
    "    print('extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # RandomForest hyperparameters\n",
    "    parser.add_argument('--n_estimators', type=int, default=10)\n",
    "    parser.add_argument('--min_samples_leaf', type=int, default=3)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train_dir', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test_dir', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    parser.add_argument('--train_file', type=str, default='california_housing_train.csv')\n",
    "    parser.add_argument('--test_file', type=str, default='california_housing_test.csv')\n",
    "    parser.add_argument('--features', type=str)  # explicitly name which features to use\n",
    "    parser.add_argument('--target_variable', type=str)  # explicitly name the column to be used as target\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    #------------------------------- data preparation\n",
    "    print('reading data')\n",
    "    train_df = pd.read_csv(os.path.join(args.train_dir, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test_dir, args.test_file))\n",
    "\n",
    "    print('building training and testing datasets')\n",
    "    X_train = train_df[args.features.split()]\n",
    "    X_test = test_df[args.features.split()]\n",
    "    y_train = train_df[args.target_variable]\n",
    "    y_test = test_df[args.target_variable]\n",
    "\n",
    "    #------------------------------- model training\n",
    "    print('training model')\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=args.n_estimators,\n",
    "        min_samples_leaf=args.min_samples_leaf,\n",
    "        n_jobs=-1)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #-------------------------------  model testing\n",
    "    print('testing model')\n",
    "    abs_err = np.abs(model.predict(X_test) - y_test)\n",
    "\n",
    "    # percentile absolute errors\n",
    "    for q in [10, 50, 90]:\n",
    "        print('AE-at-' + str(q) + 'th-percentile: '\n",
    "              + str(np.percentile(a=abs_err, q=q)))\n",
    "        \n",
    "#Mean Absolute Error is a model evaluation metric used with regression models. \n",
    "\n",
    "#------------------------------- save model\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print('model saved at ' + path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local training\n",
    "Script arguments allows us to remove from the script any SageMaker-specific configuration, and run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting arguments\n",
      "reading data\n",
      "building training and testing datasets\n",
      "training model\n",
      "testing model\n",
      "AE-at-10th-percentile: 0.031814921908952694\n",
      "AE-at-50th-percentile: 0.20358010771173296\n",
      "AE-at-90th-percentile: 0.772798234520036\n",
      "model saved at model/model.joblib\n"
     ]
    }
   ],
   "source": [
    "! python source/sklearn_training_script.py \\\n",
    "    --n_estimators 100 \\\n",
    "    --min_samples_leaf 3 \\\n",
    "    --model_dir 'model/' \\\n",
    "    --train_dir 'data/' \\\n",
    "    --test_dir 'data/' \\\n",
    "    --train_file 'california_housing_train.csv' \\\n",
    "    --test_file 'california_housing_test.csv' \\\n",
    "    --features 'MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude' \\\n",
    "    --target_variable 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data input channels (copy to S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set URI: s3://sagemaker-ap-southeast-2-006485324388/sm101/sklearn/california_housing_train.csv\n",
      "Test set URI: s3://sagemaker-ap-southeast-2-006485324388/sm101/sklearn/california_housing_test.csv\n"
     ]
    }
   ],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "train_path_s3 = sess.upload_data(\n",
    "    path='data/california_housing_train.csv',  # source\n",
    "    bucket=bucket,\n",
    "    key_prefix='sm101/sklearn'  # destination path in S3\n",
    ")\n",
    "\n",
    "test_path_s3 = sess.upload_data(\n",
    "    path='data/california_housing_test.csv',  # source\n",
    "    bucket=bucket,\n",
    "    key_prefix='sm101/sklearn'  # destination path in S3\n",
    ")\n",
    "\n",
    "print('Train set URI:', train_path_s3)\n",
    "print('Test set URI:', test_path_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching a training job with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the Estimator from the SageMaker Python SDK\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='source/sklearn_training_script.py',\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    framework_version='0.23-1',\n",
    "    base_job_name='rf-scikit',\n",
    "    metric_definitions=[\n",
    "        { 'Name': 'median-AE', 'Regex': 'AE-at-50th-percentile: ([0-9.]+).*$' },\n",
    "    ],\n",
    "    hyperparameters={\n",
    "        'n_estimators': 100,\n",
    "        'min_samples_leaf': 3,\n",
    "        'features': 'MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude',\n",
    "        'target_variable': 'label',\n",
    "    },\n",
    "    max_run=20*60,  # Maximum allowed active runtime (in seconds)\n",
    "    use_spot_instances=True,  # Use spot instances to reduce cost\n",
    "    max_wait=30*60,  # Maximum clock time (including spot delays)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-23 05:03:54 Starting - Starting the training job...\n",
      "2022-06-23 05:04:17 Starting - Preparing the instances for trainingProfilerReport-1655960634: InProgress\n",
      "............\n",
      "2022-06-23 05:06:18 Downloading - Downloading input data......\n",
      "2022-06-23 05:07:18 Training - Downloading the training image..\u001b[34m2022-06-23 05:07:37,523 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2022-06-23 05:07:37,528 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-23 05:07:37,544 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-06-23 05:07:37,923 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-23 05:07:37,941 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-23 05:07:37,962 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-23 05:07:37,979 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"features\": \"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\n",
      "        \"min_samples_leaf\": 3,\n",
      "        \"n_estimators\": 100,\n",
      "        \"target_variable\": \"target\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rf-scikit-2022-06-23-05-03-54-169\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-2-006485324388/rf-scikit-2022-06-23-05-03-54-169/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sklearn_training_script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sklearn_training_script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"features\":\"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\"min_samples_leaf\":3,\"n_estimators\":100,\"target_variable\":\"target\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=sklearn_training_script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=sklearn_training_script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-2-006485324388/rf-scikit-2022-06-23-05-03-54-169/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"features\":\"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\"min_samples_leaf\":3,\"n_estimators\":100,\"target_variable\":\"target\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rf-scikit-2022-06-23-05-03-54-169\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-2-006485324388/rf-scikit-2022-06-23-05-03-54-169/source/sourcedir.tar.gz\",\"module_name\":\"sklearn_training_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sklearn_training_script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--features\",\"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\"--min_samples_leaf\",\"3\",\"--n_estimators\",\"100\",\"--target_variable\",\"target\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURES=MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_SAMPLES_LEAF=3\u001b[0m\n",
      "\u001b[34mSM_HP_N_ESTIMATORS=100\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET_VARIABLE=target\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python sklearn_training_script.py --features MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude --min_samples_leaf 3 --n_estimators 100 --target_variable target\u001b[0m\n",
      "\u001b[34mextracting arguments\u001b[0m\n",
      "\u001b[34mreading data\u001b[0m\n",
      "\u001b[34mbuilding training and testing datasets\u001b[0m\n",
      "\u001b[34mtraining model\u001b[0m\n",
      "\n",
      "2022-06-23 05:07:55 Uploading - Uploading generated training model\u001b[34mtesting model\u001b[0m\n",
      "\u001b[34mAE-at-10th-percentile: 0.031453794408369345\u001b[0m\n",
      "\u001b[34mAE-at-50th-percentile: 0.20413999126984128\u001b[0m\n",
      "\u001b[34mAE-at-90th-percentile: 0.7697432024163903\u001b[0m\n",
      "\u001b[34mmodel saved at /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34m2022-06-23 05:07:47,627 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-06-23 05:08:18 Completed - Training job completed\n",
      "ProfilerReport-1655960634: NoIssuesFound\n",
      "Training seconds: 128\n",
      "Billable seconds: 39\n",
      "Managed Spot Training savings: 69.5%\n"
     ]
    }
   ],
   "source": [
    "sklearn_estimator.fit({'train':train_path_s3, 'test': test_path_s3}, wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the training job that we ran is very \"light\", due to the very small dataset. As such, running locally on the notebook instance results in a faster execution time, compared to SageMaker. SageMaker takes longer time to run the job because it has to provision the training infrastructure. Since this example training job not very resource-intensive, the infrastructure provisioning process adds more overhead, compared to the training job itself. \n",
    "\n",
    "In a real situation, where datasets are large, running on SageMaker can considerably speed up the execution process - and help us optimize costs, by keeping this interactive notebook environment modest and spinning up more powerful training job resources on-demand.\n",
    "\n",
    "Note that this training job *did not run here on the notebook itself*. You'll be able to see the history in the [AWS Console for SageMaker - Training Jobs tab](https://console.aws.amazon.com/sagemaker/home?#/jobs).\n",
    "\n",
    "> ℹ️ **Tip:** There's **no need to re-run** a training job if your notebook kernel restarts or the estimator state is lost for some other reason... You can just *attach* to a previous training job by name - for example:\n",
    ">\n",
    "> ```python\n",
    "> estimator = SKLearn.attach('rf-scikit-2025-01-01-00-00-00-000')\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to a real-time endpoint\n",
    "\n",
    "### Deploy with Python SDK\n",
    "\n",
    "It's possible to deploy a trained `Estimator` to a SageMaker endpoint for real-time inference in one line of code, with `Estimator.deploy(...)` - which implicitly creates a SageMaker [Model](https://console.aws.amazon.com/sagemaker/home?#/models), [Endpoint Configuration](https://console.aws.amazon.com/sagemaker/home?#/endpointConfig), and [Endpoint](https://console.aws.amazon.com/sagemaker/home?#/endpoints).\n",
    "\n",
    "For more fine-grained control though, you can choose to create a `Model` object through the SageMaker Python SDK - referencing the `model.tar.gz` produced on Amazon S3 by the training job. This would allow us to, for example:\n",
    "\n",
    "- Modify environment variables or the Python files used between training and inference\n",
    "- Import a model trained outside SageMaker that's been packaged to a compatible `model.tar.gz` on Amazon S3\n",
    "\n",
    "We'll demonstrate the longer route here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-06-23 05:08:18 Starting - Preparing the instances for training\n",
      "2022-06-23 05:08:18 Downloading - Downloading input data\n",
      "2022-06-23 05:08:18 Training - Training image download completed. Training in progress.\n",
      "2022-06-23 05:08:18 Uploading - Uploading generated training model\n",
      "2022-06-23 05:08:18 Completed - Training job completed\n",
      "Model artifact saved at: s3://sagemaker-ap-southeast-2-006485324388/rf-scikit-2022-06-23-05-03-54-169/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs='None')  # Check the job is finished\n",
    "\n",
    "model_artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name)['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "print('Model artifact saved at:', model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "model = SKLearnModel(\n",
    "    model_data=model_artifact,\n",
    "    framework_version='0.23-1',\n",
    "    py_version='py3',\n",
    "    role=get_execution_role(),\n",
    "    entry_point='source/sklearn_training_script.py',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    instance_type='ml.c5.large',\n",
    "    initial_instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realtime inference\n",
    "\n",
    "The [Predictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html) class from the SageMaker Python SDK provides a Python wrapper around the endpoint which also handles (configurable) de/serialization of the request and response.\n",
    "\n",
    "Alternatively for clients which cannot use the SageMaker Python SDK (for example non-Python clients, or Python environments where the PyPI [sagemaker](https://pypi.org/project/sagemaker/) package can't be installed for some reason): The general AWS SDKs can be used to call the lower-level [SageMaker InvokeEndpoint API](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_runtime_InvokeEndpoint.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49843665 0.79757191 4.82132077 ... 1.24381684 3.04654679 4.10759263]\n"
     ]
    }
   ],
   "source": [
    "# the SKLearnPredictor does the serialization from pandas for us\n",
    "print(predictor.predict(testX[data.feature_names]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "nl\n",
      "      MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0     1.6812      25.0  4.192201   1.022284      1392.0  3.877437     36.06   \n",
      "1     2.5313      30.0  5.039384   1.193493      1565.0  2.679795     35.14   \n",
      "2     3.4801      52.0  3.977155   1.185877      1310.0  1.360332     37.80   \n",
      "3     5.7376      17.0  6.163636   1.020202      1705.0  3.444444     34.28   \n",
      "4     3.7250      34.0  5.492991   1.028037      1063.0  2.483645     36.62   \n",
      "...      ...       ...       ...        ...         ...       ...       ...   \n",
      "5155  6.6260      51.0  5.532213   0.974790       771.0  2.159664     34.04   \n",
      "5156  2.1898      30.0  4.509091   0.945455       410.0  2.484848     40.18   \n",
      "5157  2.1667      37.0  3.272152   1.056962      2173.0  4.584388     34.02   \n",
      "5158  6.8869       6.0  7.382385   1.030075      2354.0  2.528464     38.51   \n",
      "5159  6.6321      36.0  5.734644   1.056511      1033.0  2.538084     33.89   \n",
      "\n",
      "      Longitude  \n",
      "0       -119.01  \n",
      "1       -119.46  \n",
      "2       -122.44  \n",
      "3       -118.72  \n",
      "4       -121.93  \n",
      "...         ...  \n",
      "5155    -118.42  \n",
      "5156    -122.21  \n",
      "5157    -118.26  \n",
      "5158    -121.06  \n",
      "5159    -118.40  \n",
      "\n",
      "[5160 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.feature_names)\n",
    "print('nl')\n",
    "print(testX[data.feature_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete endpoint\n",
    "\n",
    "While training job infrastructure is started on-demand and terminated as soon as the job stops, endpoints are live until we turn them off. Delete unused endpoints to prevent ongoing costs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

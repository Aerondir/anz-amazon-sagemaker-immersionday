{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Iris Classifier - Local Example\n",
    "\n",
    "_**Train and export a scikit-learn classifier for the [Iris data set](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data) dataset: Performing all storage and computation locally on the notebook.**_\n",
    "\n",
    "This notebook works well with the `Python 3 (Data science)` kernel on SageMaker Studio, or `conda_python 3` on classic SageMaker Notebook Instances.\n",
    "\n",
    "---\n",
    "\n",
    "The [dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/) is hosted in the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) and maintain 622 data sets.\n",
    "\n",
    ">‚ùì*Can you figure out how to re-create this notebook's workflow using SageMaker more effectively?*\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. **[Prepare the Data](#Prepare-the-Data)**\n",
    "1. **[Load the Data From File](#Load-the-Data-From-File)**\n",
    "1. **[Pre-Process the Data for our CNN](#Pre-Process-the-Data-for-our-CNN)**\n",
    "1. **[Build a Model](#Build-a-Model)**\n",
    "1. **[Fit the Model](#Fit-the-Model)**\n",
    "1. **[Save the Trained Model](#Save-the-Trained-Model)**\n",
    "1. **[Explore Results](#Explore-Results)**\n",
    "\n",
    "See the accompanying **Instructions** notebook for more guidance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "Now let's download the image data.\n",
    "\n",
    "The original MNIST data has 70000 small 28x28 pixel PNG files (60000 in the training dataset, and 10000 in the test dataset). This format is nice and familiar - but a large number of tiny files is inefficient for storage and transfer - so **to keep things performant** we will:\n",
    "\n",
    "- Download the data to a local temporary folder under `/tmp` (meaning you won't see the files in the left sidebar in SageMaker)\n",
    "- Sample just a subset of the data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to encode labels to codes\n",
    "label_encode = {\n",
    "    'Iris-virginica': 0,\n",
    "    'Iris-versicolor': 1,\n",
    "    'Iris-setosa': 2\n",
    "}\n",
    "\n",
    "# Dictionary to convert codes to labels\n",
    "label_decode = {\n",
    "    0: 'Iris-virginica',\n",
    "    1: 'Iris-versicolor',\n",
    "    2: 'Iris-setosa'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data = pd.read_csv('iris.data', \n",
    "                   names=['sepal length', 'sepal width', \n",
    "                          'petal length', 'petal width', \n",
    "                          'label'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "Y_encoded = data['label'].map(label_encode)\n",
    "X =  data.drop([\"label\"], axis=1)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, Y_encoded, test_size=0.2) \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(train_X)\n",
    "X_test = sc.fit_transform(test_X)\n",
    "# print(X_train)   \n",
    "# print(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model\n",
    "\n",
    "The model chosen from the Scikit- learn classifiers, is the widely used logistic regression model and takes the features and labels as input and returns the predicted lable or the probabilities (if chosen) as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the logistic regression model\n",
    "model = LogisticRegression().fit(X_train, train_y)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model\n",
    "\n",
    "Scikit-learn makes fitting and evaluating the model straightforward enough: We don't have any fancy hooks, and are happy with the default logging:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Trained Model\n",
    "\n",
    "We use Joblib to save the model and then load it for prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Joblib to save the model \n",
    "# see scikit learn documentation here:https://scikit-learn.org/stable/model_persistence.html\n",
    "joblib.dump(model, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Explore Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model using joblib\n",
    "model = joblib.load(\"model.joblib\")\n",
    "\n",
    "#get the data to predict\n",
    "result = loaded_model.predict(X_test)\n",
    "results=' | '.join([label_decode[t] for t in result])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done!\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
